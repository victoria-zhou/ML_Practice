{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL - Extract, Transform, Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='../data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # 1 input \n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (5) hidden linear layer \n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "        \n",
    "    def begin_run(self, run, network, loader):\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('image', grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "           \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "                                \n",
    "    def end_epoch(self):\n",
    "\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for k,v in self.run_params._asdict().items(): \n",
    "            results[k] = v\n",
    "            self.run_data.append(results)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        \n",
    "    def track_loss(self, loss, batch):\n",
    "        self.epoch_loss += loss.item() * batch[0].shape[0]\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "        \n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.036083</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>13.109646</td>\n",
       "      <td>13.808707</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.559073</td>\n",
       "      <td>0.782850</td>\n",
       "      <td>13.755945</td>\n",
       "      <td>27.667713</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.463450</td>\n",
       "      <td>0.828983</td>\n",
       "      <td>13.461522</td>\n",
       "      <td>41.212512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>0.851100</td>\n",
       "      <td>12.988818</td>\n",
       "      <td>54.279294</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.369549</td>\n",
       "      <td>0.863133</td>\n",
       "      <td>14.063079</td>\n",
       "      <td>68.418623</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.288689</td>\n",
       "      <td>0.506900</td>\n",
       "      <td>12.866314</td>\n",
       "      <td>14.301904</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.688726</td>\n",
       "      <td>0.728217</td>\n",
       "      <td>12.378830</td>\n",
       "      <td>26.751441</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.573809</td>\n",
       "      <td>0.771433</td>\n",
       "      <td>12.109697</td>\n",
       "      <td>38.940450</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518170</td>\n",
       "      <td>0.799100</td>\n",
       "      <td>12.270801</td>\n",
       "      <td>51.285186</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.470654</td>\n",
       "      <td>0.824450</td>\n",
       "      <td>12.369275</td>\n",
       "      <td>63.729012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0    1      1  1.036083  0.597333       13.109646     13.808707  0.01   \n",
       "1    1      2  0.559073  0.782850       13.755945     27.667713  0.01   \n",
       "2    1      3  0.463450  0.828983       13.461522     41.212512  0.01   \n",
       "3    1      4  0.402669  0.851100       12.988818     54.279294  0.01   \n",
       "4    1      5  0.369549  0.863133       14.063079     68.418623  0.01   \n",
       "5    2      1  1.288689  0.506900       12.866314     14.301904  0.01   \n",
       "6    2      2  0.688726  0.728217       12.378830     26.751441  0.01   \n",
       "7    2      3  0.573809  0.771433       12.109697     38.940450  0.01   \n",
       "8    2      4  0.518170  0.799100       12.270801     51.285186  0.01   \n",
       "9    2      5  0.470654  0.824450       12.369275     63.729012  0.01   \n",
       "\n",
       "   batch_size  \n",
       "0        1000  \n",
       "1        1000  \n",
       "2        1000  \n",
       "3        1000  \n",
       "4        1000  \n",
       "5        2000  \n",
       "6        2000  \n",
       "7        2000  \n",
       "8        2000  \n",
       "9        2000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000, 2000]\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    network = Network()\n",
    "    loader = DataLoader(train_set, batch_size=run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader: # Get Batch\n",
    "            \n",
    "            images, labels = batch \n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "            optimizer.zero_grad() # this is used because the weights would be accumulated if not reset to zero\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "            \n",
    "            m.track_loss(loss, batch)\n",
    "            m.track_num_correct(preds, labels)\n",
    "            \n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [1000, 10000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Run(lr=0.01, batch_size=1000)\n",
      "-Run(lr=0.01, batch_size=10000)\n",
      "-Run(lr=0.001, batch_size=1000)\n",
      "-Run(lr=0.001, batch_size=10000)\n"
     ]
    }
   ],
   "source": [
    "for run in RunBuilder.get_runs(params):\n",
    "    comment = f'-{run}'\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above is the same as below step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr', 'batch_size'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[0.01, 0.001], [1000, 10000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = namedtuple('Run', params.keys()) # set the parameters ordered\n",
    "runs = []\n",
    "for v in product(*params.values()):\n",
    "    runs.append(Run(*v)) # add the values for the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=1000),\n",
       " Run(lr=0.01, batch_size=10000),\n",
       " Run(lr=0.001, batch_size=1000),\n",
       " Run(lr=0.001, batch_size=10000)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best part about TensorBoard is its out-of-the-box capability of tracking \n",
    "# our hyperparameters over time and across runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard Histograms And Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [100, 1000], [True, False]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [100, 1000]\n",
    "    ,shuffle = [True, False]\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46196 loss: 35514.61341679096\n",
      "epoch 1 total_correct: 51020 loss: 24499.457749724388\n",
      "epoch 2 total_correct: 51877 loss: 22003.507828712463\n",
      "epoch 0 total_correct: 52089 loss: 21535.288953781128\n",
      "epoch 1 total_correct: 52514 loss: 20343.014292418957\n",
      "epoch 2 total_correct: 52736 loss: 19872.757725417614\n",
      "epoch 0 total_correct: 53688 loss: 16914.28190469742\n",
      "epoch 1 total_correct: 54034 loss: 15656.790286302567\n",
      "epoch 2 total_correct: 54240 loss: 15146.981626749039\n",
      "epoch 0 total_correct: 54234 loss: 15078.522741794586\n",
      "epoch 1 total_correct: 54499 loss: 14334.07486975193\n",
      "epoch 2 total_correct: 54618 loss: 14164.20367360115\n",
      "epoch 0 total_correct: 54966 loss: 12930.421817302704\n",
      "epoch 1 total_correct: 55124 loss: 12544.62364912033\n",
      "epoch 2 total_correct: 55178 loss: 12317.50683709979\n",
      "epoch 0 total_correct: 55223 loss: 12145.948259532452\n",
      "epoch 1 total_correct: 55334 loss: 11961.580868065357\n",
      "epoch 2 total_correct: 55398 loss: 11788.014801591635\n",
      "epoch 0 total_correct: 55422 loss: 11666.854336857796\n",
      "epoch 1 total_correct: 55456 loss: 11471.859827637672\n",
      "epoch 2 total_correct: 55518 loss: 11347.577437758446\n",
      "epoch 0 total_correct: 55568 loss: 11295.866191387177\n",
      "epoch 1 total_correct: 55581 loss: 11173.75060915947\n",
      "epoch 2 total_correct: 55635 loss: 11082.033231854439\n"
     ]
    }
   ],
   "source": [
    "# example of a complete loop\n",
    "network = Network()\n",
    "\n",
    "for lr, batch_size, shuffle in product(*param_values): \n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    tb = SummaryWriter()\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    for epoch in range(3):\n",
    "\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader: # Get Batch\n",
    "\n",
    "            images, labels = batch \n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "            optimizer.zero_grad() # this is used because the weights would be accumulated if not reset to zero\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            total_loss += loss.item()* images.shape[0] # 1\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "        print(\n",
    "            \"epoch\", epoch, \n",
    "            \"total_correct:\", total_correct, \n",
    "            \"loss:\", total_loss\n",
    "        )\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 For every batch, we are using the batch_size variable to update the total_loss value. \n",
    "# 1 We are scaling up the average loss value of the samples in the batch by the batch_size value. \n",
    "# 1 However, as we have just discussed, sometimes the last batch will contain fewer samples. \n",
    "# 1 Thus, scaling by the predefined batch_size value is inaccurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
