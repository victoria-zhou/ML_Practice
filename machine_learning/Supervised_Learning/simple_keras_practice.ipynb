{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # the 5% of younger unduvuduals who did experience side effects\n",
    "    random_younger = randint(13, 65)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    # the 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(100):\n",
    "    \n",
    "    # the 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    # the 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "89\n",
      "56\n",
      "95\n",
      "38\n",
      "87\n",
      "37\n",
      "99\n",
      "44\n",
      "98\n",
      "36\n",
      "67\n",
      "65\n",
      "70\n",
      "43\n",
      "97\n",
      "40\n",
      "75\n",
      "36\n",
      "80\n",
      "29\n",
      "75\n",
      "22\n",
      "72\n",
      "15\n",
      "78\n",
      "17\n",
      "87\n",
      "56\n",
      "78\n",
      "32\n",
      "81\n",
      "44\n",
      "82\n",
      "33\n",
      "86\n",
      "49\n",
      "77\n",
      "65\n",
      "86\n",
      "49\n",
      "89\n",
      "56\n",
      "71\n",
      "23\n",
      "70\n",
      "59\n",
      "66\n",
      "63\n",
      "99\n",
      "39\n",
      "96\n",
      "32\n",
      "75\n",
      "13\n",
      "66\n",
      "30\n",
      "87\n",
      "39\n",
      "95\n",
      "15\n",
      "77\n",
      "40\n",
      "99\n",
      "53\n",
      "89\n",
      "35\n",
      "67\n",
      "17\n",
      "72\n",
      "31\n",
      "79\n",
      "65\n",
      "85\n",
      "37\n",
      "89\n",
      "48\n",
      "94\n",
      "44\n",
      "74\n",
      "14\n",
      "98\n",
      "17\n",
      "82\n",
      "49\n",
      "74\n",
      "14\n",
      "98\n",
      "62\n",
      "67\n",
      "29\n",
      "82\n",
      "37\n",
      "69\n",
      "65\n",
      "86\n",
      "52\n",
      "82\n",
      "65\n",
      "75\n",
      "18\n",
      "80\n",
      "25\n",
      "69\n",
      "62\n",
      "77\n",
      "38\n",
      "67\n",
      "61\n",
      "94\n",
      "53\n",
      "69\n",
      "64\n",
      "98\n",
      "42\n",
      "65\n",
      "63\n",
      "86\n",
      "42\n",
      "71\n",
      "36\n",
      "67\n",
      "33\n",
      "95\n",
      "42\n",
      "73\n",
      "49\n",
      "94\n",
      "21\n",
      "72\n",
      "28\n",
      "88\n",
      "34\n",
      "87\n",
      "34\n",
      "97\n",
      "19\n",
      "85\n",
      "28\n",
      "89\n",
      "17\n",
      "95\n",
      "33\n",
      "69\n",
      "40\n",
      "91\n",
      "61\n",
      "76\n",
      "24\n",
      "96\n",
      "21\n",
      "84\n",
      "15\n",
      "94\n",
      "60\n",
      "71\n",
      "15\n",
      "80\n",
      "29\n",
      "90\n",
      "36\n",
      "65\n",
      "47\n",
      "91\n",
      "19\n",
      "90\n",
      "15\n",
      "77\n",
      "61\n",
      "73\n",
      "62\n",
      "72\n",
      "15\n",
      "98\n",
      "60\n",
      "100\n",
      "24\n",
      "76\n",
      "25\n",
      "87\n",
      "49\n",
      "88\n",
      "39\n",
      "75\n",
      "35\n",
      "91\n",
      "19\n",
      "74\n",
      "34\n",
      "95\n",
      "59\n",
      "86\n",
      "38\n",
      "92\n",
      "31\n",
      "89\n",
      "33\n",
      "83\n",
      "63\n",
      "93\n",
      "35\n",
      "73\n",
      "56\n",
      "67\n",
      "39\n",
      "83\n",
      "19\n",
      "68\n",
      "28\n",
      "93\n",
      "46\n",
      "69\n",
      "27\n",
      "77\n",
      "49\n",
      "92\n",
      "37\n",
      "68\n",
      "15\n",
      "96\n",
      "46\n",
      "84\n",
      "24\n",
      "88\n",
      "15\n",
      "97\n",
      "13\n",
      "91\n",
      "43\n",
      "97\n",
      "38\n",
      "75\n",
      "53\n",
      "86\n",
      "16\n",
      "89\n",
      "30\n",
      "76\n",
      "28\n",
      "79\n",
      "59\n",
      "94\n",
      "16\n",
      "72\n",
      "19\n",
      "66\n",
      "56\n",
      "74\n",
      "26\n",
      "74\n",
      "62\n",
      "67\n",
      "39\n",
      "76\n",
      "54\n",
      "87\n",
      "27\n",
      "91\n",
      "57\n",
      "68\n",
      "16\n",
      "76\n",
      "60\n",
      "95\n",
      "63\n",
      "86\n",
      "26\n",
      "72\n",
      "55\n",
      "73\n",
      "50\n",
      "68\n",
      "19\n",
      "80\n",
      "33\n",
      "94\n",
      "23\n",
      "99\n",
      "44\n",
      "74\n",
      "40\n",
      "83\n",
      "43\n",
      "81\n",
      "40\n",
      "74\n",
      "64\n",
      "98\n",
      "17\n",
      "73\n",
      "62\n",
      "99\n",
      "13\n",
      "82\n",
      "31\n",
      "96\n",
      "48\n",
      "100\n",
      "14\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "for i in train_samples:\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in train_labels:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18390805]\n",
      "[0.27586207]\n",
      "[0.93103448]\n",
      "[0.02298851]\n",
      "[0.35632184]\n",
      "[0.4137931]\n",
      "[0.8045977]\n",
      "[0.71264368]\n",
      "[0.87356322]\n",
      "[0.17241379]\n",
      "[0.62068966]\n",
      "[0.95402299]\n",
      "[0.4137931]\n",
      "[0.87356322]\n",
      "[0.22988506]\n",
      "[0.63218391]\n",
      "[0.45977011]\n",
      "[0.73563218]\n",
      "[0.98850575]\n",
      "[1.]\n",
      "[0.29885057]\n",
      "[0.03448276]\n",
      "[0.22988506]\n",
      "[0.93103448]\n",
      "[0.97701149]\n",
      "[0.93103448]\n",
      "[0.66666667]\n",
      "[0.67816092]\n",
      "[0.04597701]\n",
      "[0.40229885]\n",
      "[0.59770115]\n",
      "[0.89655172]\n",
      "[0.72413793]\n",
      "[0.66666667]\n",
      "[0.77011494]\n",
      "[0.02298851]\n",
      "[0.77011494]\n",
      "[0.35632184]\n",
      "[0.70114943]\n",
      "[0.85057471]\n",
      "[0.97701149]\n",
      "[0.54022989]\n",
      "[0.49425287]\n",
      "[0.12643678]\n",
      "[0.73563218]\n",
      "[0.22988506]\n",
      "[0.63218391]\n",
      "[0.87356322]\n",
      "[0.90804598]\n",
      "[0.37931034]\n",
      "[0.56321839]\n",
      "[0.57471264]\n",
      "[0.72413793]\n",
      "[0.28735632]\n",
      "[0.04597701]\n",
      "[0.68965517]\n",
      "[0.68965517]\n",
      "[0.85057471]\n",
      "[0.62068966]\n",
      "[0.02298851]\n",
      "[0.67816092]\n",
      "[0.67816092]\n",
      "[0.27586207]\n",
      "[0.35632184]\n",
      "[0.90804598]\n",
      "[0.70114943]\n",
      "[0.98850575]\n",
      "[0.11494253]\n",
      "[0.95402299]\n",
      "[0.17241379]\n",
      "[0.74712644]\n",
      "[0.71264368]\n",
      "[0.7816092]\n",
      "[0.04597701]\n",
      "[0.06896552]\n",
      "[0.2183908]\n",
      "[0.03448276]\n",
      "[0.8045977]\n",
      "[0.83908046]\n",
      "[0.70114943]\n",
      "[0.]\n",
      "[0.06896552]\n",
      "[0.67816092]\n",
      "[0.29885057]\n",
      "[0.1954023]\n",
      "[0.75862069]\n",
      "[0.97701149]\n",
      "[0.06896552]\n",
      "[0.02298851]\n",
      "[0.95402299]\n",
      "[0.5862069]\n",
      "[0.42528736]\n",
      "[0.45977011]\n",
      "[0.93103448]\n",
      "[0.18390805]\n",
      "[0.02298851]\n",
      "[0.26436782]\n",
      "[0.89655172]\n",
      "[0.14942529]\n",
      "[0.35632184]\n",
      "[0.37931034]\n",
      "[0.01149425]\n",
      "[0.25287356]\n",
      "[0.62068966]\n",
      "[0.25287356]\n",
      "[0.17241379]\n",
      "[0.09195402]\n",
      "[0.64367816]\n",
      "[0.98850575]\n",
      "[0.83908046]\n",
      "[0.70114943]\n",
      "[0.34482759]\n",
      "[0.28735632]\n",
      "[0.96551724]\n",
      "[0.06896552]\n",
      "[0.52873563]\n",
      "[0.85057471]\n",
      "[0.59770115]\n",
      "[0.75862069]\n",
      "[0.5862069]\n",
      "[0.20689655]\n",
      "[0.83908046]\n",
      "[0.3908046]\n",
      "[0.09195402]\n",
      "[0.70114943]\n",
      "[0.47126437]\n",
      "[0.70114943]\n",
      "[0.29885057]\n",
      "[0.4137931]\n",
      "[0.55172414]\n",
      "[0.59770115]\n",
      "[0.79310345]\n",
      "[0.59770115]\n",
      "[0.22988506]\n",
      "[0.34482759]\n",
      "[0.85057471]\n",
      "[0.48275862]\n",
      "[0.22988506]\n",
      "[0.55172414]\n",
      "[0.05747126]\n",
      "[0.33333333]\n",
      "[0.56321839]\n",
      "[0.89655172]\n",
      "[0.79310345]\n",
      "[0.81609195]\n",
      "[0.66666667]\n",
      "[0.86206897]\n",
      "[0.86206897]\n",
      "[0.6091954]\n",
      "[0.55172414]\n",
      "[0.49425287]\n",
      "[0.59770115]\n",
      "[0.12643678]\n",
      "[0.14942529]\n",
      "[0.06896552]\n",
      "[0.86206897]\n",
      "[0.71264368]\n",
      "[0.95402299]\n",
      "[0.17241379]\n",
      "[0.54022989]\n",
      "[0.26436782]\n",
      "[0.97701149]\n",
      "[0.12643678]\n",
      "[0.79310345]\n",
      "[0.49425287]\n",
      "[0.72413793]\n",
      "[0.]\n",
      "[0.56321839]\n",
      "[0.68965517]\n",
      "[0.24137931]\n",
      "[0.96551724]\n",
      "[0.64367816]\n",
      "[0.6091954]\n",
      "[0.20689655]\n",
      "[0.94252874]\n",
      "[0.71264368]\n",
      "[0.83908046]\n",
      "[0.77011494]\n",
      "[0.94252874]\n",
      "[0.82758621]\n",
      "[0.98850575]\n",
      "[0.73563218]\n",
      "[0.62068966]\n",
      "[1.]\n",
      "[0.13793103]\n",
      "[0.71264368]\n",
      "[0.31034483]\n",
      "[0.31034483]\n",
      "[0.87356322]\n",
      "[0.11494253]\n",
      "[0.86206897]\n",
      "[0.]\n",
      "[0.01149425]\n",
      "[0.87356322]\n",
      "[0.97701149]\n",
      "[0.02298851]\n",
      "[0.26436782]\n",
      "[0.89655172]\n",
      "[0.01149425]\n",
      "[0.94252874]\n",
      "[0.27586207]\n",
      "[0.57471264]\n",
      "[0.65517241]\n",
      "[0.93103448]\n",
      "[0.24137931]\n",
      "[0.81609195]\n",
      "[0.06896552]\n",
      "[0.34482759]\n",
      "[0.91954023]\n",
      "[0.64367816]\n",
      "[0.59770115]\n",
      "[0.2183908]\n",
      "[0.52873563]\n",
      "[0.72413793]\n",
      "[0.33333333]\n",
      "[0.83908046]\n",
      "[0.83908046]\n",
      "[0.88505747]\n",
      "[0.10344828]\n",
      "[0.79310345]\n",
      "[0.57471264]\n",
      "[0.28735632]\n",
      "[0.18390805]\n",
      "[0.31034483]\n",
      "[0.63218391]\n",
      "[0.67816092]\n",
      "[0.6091954]\n",
      "[0.94252874]\n",
      "[0.87356322]\n",
      "[0.02298851]\n",
      "[0.85057471]\n",
      "[0.56321839]\n",
      "[0.4137931]\n",
      "[0.4137931]\n",
      "[0.24137931]\n",
      "[0.03448276]\n",
      "[0.29885057]\n",
      "[0.67816092]\n",
      "[0.77011494]\n",
      "[0.45977011]\n",
      "[0.50574713]\n",
      "[0.97701149]\n",
      "[0.59770115]\n",
      "[0.62068966]\n",
      "[0.44827586]\n",
      "[0.62068966]\n",
      "[0.79310345]\n",
      "[0.72413793]\n",
      "[0.28735632]\n",
      "[0.65517241]\n",
      "[0.87356322]\n",
      "[0.73563218]\n",
      "[0.62068966]\n",
      "[0.8045977]\n",
      "[0.68965517]\n",
      "[0.94252874]\n",
      "[0.57471264]\n",
      "[0.02298851]\n",
      "[0.83908046]\n",
      "[0.63218391]\n",
      "[0.31034483]\n",
      "[0.74712644]\n",
      "[0.96551724]\n",
      "[0.64367816]\n",
      "[0.20689655]\n",
      "[0.71264368]\n",
      "[0.04597701]\n",
      "[0.16091954]\n",
      "[0.56321839]\n",
      "[0.68965517]\n",
      "[0.88505747]\n",
      "[0.91954023]\n",
      "[0.49425287]\n",
      "[0.89655172]\n",
      "[0.27586207]\n",
      "[0.16091954]\n",
      "[0.54022989]\n",
      "[0.82758621]\n",
      "[0.57471264]\n",
      "[0.70114943]\n",
      "[0.04597701]\n",
      "[0.31034483]\n",
      "[0.7816092]\n",
      "[0.73563218]\n",
      "[0.94252874]\n",
      "[0.40229885]\n",
      "[0.49425287]\n",
      "[0.93103448]\n",
      "[0.33333333]\n",
      "[0.85057471]\n",
      "[0.29885057]\n",
      "[0.26436782]\n",
      "[0.25287356]\n",
      "[0.1954023]\n",
      "[0.4137931]\n",
      "[0.98850575]\n",
      "[0.96551724]\n",
      "[0.64367816]\n",
      "[0.13793103]\n",
      "[0.52873563]\n"
     ]
    }
   ],
   "source": [
    "for i in scaled_train_samples:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/30\n",
      "270/270 - 1s - loss: 0.6833 - accuracy: 0.4963 - val_loss: 0.6825 - val_accuracy: 0.5333\n",
      "Epoch 2/30\n",
      "270/270 - 0s - loss: 0.6828 - accuracy: 0.5037 - val_loss: 0.6824 - val_accuracy: 0.5333\n",
      "Epoch 3/30\n",
      "270/270 - 0s - loss: 0.6823 - accuracy: 0.5222 - val_loss: 0.6821 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "270/270 - 0s - loss: 0.6819 - accuracy: 0.5259 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "270/270 - 0s - loss: 0.6814 - accuracy: 0.5481 - val_loss: 0.6816 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "270/270 - 0s - loss: 0.6810 - accuracy: 0.5481 - val_loss: 0.6813 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "270/270 - 0s - loss: 0.6806 - accuracy: 0.5519 - val_loss: 0.6811 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "270/270 - 0s - loss: 0.6802 - accuracy: 0.5519 - val_loss: 0.6808 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "270/270 - 0s - loss: 0.6798 - accuracy: 0.5630 - val_loss: 0.6806 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "270/270 - 0s - loss: 0.6795 - accuracy: 0.5667 - val_loss: 0.6803 - val_accuracy: 0.5333\n",
      "Epoch 11/30\n",
      "270/270 - 0s - loss: 0.6790 - accuracy: 0.5704 - val_loss: 0.6801 - val_accuracy: 0.5333\n",
      "Epoch 12/30\n",
      "270/270 - 0s - loss: 0.6786 - accuracy: 0.5778 - val_loss: 0.6799 - val_accuracy: 0.5667\n",
      "Epoch 13/30\n",
      "270/270 - 0s - loss: 0.6782 - accuracy: 0.5815 - val_loss: 0.6797 - val_accuracy: 0.5667\n",
      "Epoch 14/30\n",
      "270/270 - 0s - loss: 0.6780 - accuracy: 0.5889 - val_loss: 0.6794 - val_accuracy: 0.5667\n",
      "Epoch 15/30\n",
      "270/270 - 0s - loss: 0.6776 - accuracy: 0.5889 - val_loss: 0.6792 - val_accuracy: 0.5667\n",
      "Epoch 16/30\n",
      "270/270 - 0s - loss: 0.6772 - accuracy: 0.5926 - val_loss: 0.6789 - val_accuracy: 0.5333\n",
      "Epoch 17/30\n",
      "270/270 - 0s - loss: 0.6770 - accuracy: 0.5963 - val_loss: 0.6788 - val_accuracy: 0.5333\n",
      "Epoch 18/30\n",
      "270/270 - 0s - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6784 - val_accuracy: 0.5333\n",
      "Epoch 19/30\n",
      "270/270 - 0s - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6782 - val_accuracy: 0.5333\n",
      "Epoch 20/30\n",
      "270/270 - 0s - loss: 0.6757 - accuracy: 0.5889 - val_loss: 0.6779 - val_accuracy: 0.5333\n",
      "Epoch 21/30\n",
      "270/270 - 0s - loss: 0.6754 - accuracy: 0.6000 - val_loss: 0.6777 - val_accuracy: 0.5333\n",
      "Epoch 22/30\n",
      "270/270 - 0s - loss: 0.6751 - accuracy: 0.6000 - val_loss: 0.6774 - val_accuracy: 0.5333\n",
      "Epoch 23/30\n",
      "270/270 - 0s - loss: 0.6748 - accuracy: 0.6000 - val_loss: 0.6772 - val_accuracy: 0.5333\n",
      "Epoch 24/30\n",
      "270/270 - 0s - loss: 0.6743 - accuracy: 0.6111 - val_loss: 0.6770 - val_accuracy: 0.5667\n",
      "Epoch 25/30\n",
      "270/270 - 0s - loss: 0.6739 - accuracy: 0.6111 - val_loss: 0.6767 - val_accuracy: 0.5667\n",
      "Epoch 26/30\n",
      "270/270 - 0s - loss: 0.6736 - accuracy: 0.6148 - val_loss: 0.6765 - val_accuracy: 0.5333\n",
      "Epoch 27/30\n",
      "270/270 - 0s - loss: 0.6733 - accuracy: 0.6148 - val_loss: 0.6763 - val_accuracy: 0.5333\n",
      "Epoch 28/30\n",
      "270/270 - 0s - loss: 0.6729 - accuracy: 0.6148 - val_loss: 0.6760 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "270/270 - 0s - loss: 0.6725 - accuracy: 0.6111 - val_loss: 0.6758 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "270/270 - 0s - loss: 0.6722 - accuracy: 0.6148 - val_loss: 0.6756 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff649244a50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if validation_split is used, the sample/input needs to be shuffled first\n",
    "# before run below as, the shuffle parameter in below fit function, only\n",
    "# shuffles data after the x percent of validation data has been taken off\n",
    "# from the training data. that is to say, the validation data will\n",
    "# not be shuffuled\n",
    "\n",
    "model.fit(x=scaled_train_samples, y=train_labels,\n",
    "          validation_split=0.1,\n",
    "          batch_size=10, epochs=30,\n",
    "         shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lables = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # the 5% of young individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_lables.append(1)\n",
    "    \n",
    "    # the 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_lables.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    # the 95% of young individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_lables.append(0)\n",
    "    \n",
    "    # the 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_lables.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lables = np.array(test_lables)\n",
    "test_samples = np.array(test_samples)\n",
    "test_lables, test_samples = shuffle(test_lables, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5074955  0.49250445]\n",
      "[0.5074955  0.49250445]\n",
      "[0.52813846 0.47186154]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.5126972 0.4873028]\n",
      "[0.49882302 0.50117695]\n",
      "[0.4504173 0.5495827]\n",
      "[0.44698462 0.5530154 ]\n",
      "[0.4745604 0.5254396]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.435012   0.56498796]\n",
      "[0.5178961  0.48210385]\n",
      "[0.4745604 0.5254396]\n",
      "[0.5226706  0.47732928]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.45385468 0.54614526]\n",
      "[0.5277735 0.4722265]\n",
      "[0.48321775 0.51678216]\n",
      "[0.40795007 0.59204996]\n",
      "[0.48321775 0.51678216]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.39644432 0.6035557 ]\n",
      "[0.5196283  0.48037165]\n",
      "[0.44184518 0.5581549 ]\n",
      "[0.42480922 0.5751907 ]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.44355696 0.55644304]\n",
      "[0.48321775 0.51678216]\n",
      "[0.45385468 0.54614526]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.42820352 0.5717965 ]\n",
      "[0.39966217 0.6003378 ]\n",
      "[0.5040268 0.4959732]\n",
      "[0.39483866 0.60516125]\n",
      "[0.40795007 0.59204996]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.5022922  0.49770775]\n",
      "[0.524154   0.47584602]\n",
      "[0.45385468 0.54614526]\n",
      "[0.5144305  0.48556945]\n",
      "[0.4676452 0.5323548]\n",
      "[0.47283056 0.5271694 ]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.5226706  0.47732928]\n",
      "[0.5005576 0.4994423]\n",
      "[0.469373  0.5306271]\n",
      "[0.48321775 0.51678216]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.43671805 0.5632819 ]\n",
      "[0.49361956 0.5063805 ]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.45385468 0.54614526]\n",
      "[0.435012   0.56498796]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.46074244 0.5392575 ]\n",
      "[0.45213547 0.5478646 ]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.4504173 0.5495827]\n",
      "[0.40460274 0.59539723]\n",
      "[0.4676452 0.5323548]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.4504173 0.5495827]\n",
      "[0.5226706  0.47732928]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.4797533 0.5202466]\n",
      "[0.5040268 0.4959732]\n",
      "[0.5005576 0.4994423]\n",
      "[0.4163552 0.5836448]\n",
      "[0.5074955  0.49250445]\n",
      "[0.52126575 0.47873428]\n",
      "[0.459019 0.540981]\n",
      "[0.5144305  0.48556945]\n",
      "[0.49882302 0.50117695]\n",
      "[0.40795007 0.59204996]\n",
      "[0.4299032 0.5700968]\n",
      "[0.4504173 0.5495827]\n",
      "[0.49708846 0.50291157]\n",
      "[0.4197312  0.58026874]\n",
      "[0.46246684 0.53753316]\n",
      "[0.40460274 0.59539723]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.44184518 0.5581549 ]\n",
      "[0.52692527 0.4730748 ]\n",
      "[0.4555751 0.5444249]\n",
      "[0.43842563 0.56157434]\n",
      "[0.39483866 0.60516125]\n",
      "[0.52501184 0.4749882 ]\n",
      "[0.44698462 0.5530154 ]\n",
      "[0.44184518 0.5581549 ]\n",
      "[0.42820352 0.5717965 ]\n",
      "[0.40627536 0.59372467]\n",
      "[0.4504173 0.5495827]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.49535394 0.50464606]\n",
      "[0.524154   0.47584602]\n",
      "[0.5005576 0.4994423]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.48321775 0.51678216]\n",
      "[0.4555751 0.5444249]\n",
      "[0.3980521  0.60194784]\n",
      "[0.52813846 0.47186154]\n",
      "[0.4163552 0.5836448]\n",
      "[0.52393705 0.47606295]\n",
      "[0.39966217 0.6003378 ]\n",
      "[0.4676452 0.5323548]\n",
      "[0.49188524 0.5081147 ]\n",
      "[0.43671805 0.5632819 ]\n",
      "[0.5238434  0.47615665]\n",
      "[0.39483866 0.60516125]\n",
      "[0.40962693 0.590373  ]\n",
      "[0.52501184 0.4749882 ]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.46591824 0.5340817 ]\n",
      "[0.5258462 0.4741538]\n",
      "[0.4676452 0.5323548]\n",
      "[0.5005576 0.4994423]\n",
      "[0.4555751 0.5444249]\n",
      "[0.4299032 0.5700968]\n",
      "[0.4299032 0.5700968]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.5274008  0.47259927]\n",
      "[0.524154   0.47584602]\n",
      "[0.47283056 0.5271694 ]\n",
      "[0.5277735 0.4722265]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.3980521  0.60194784]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.40627536 0.59372467]\n",
      "[0.3980521  0.60194784]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.4197312  0.58026874]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.45729652 0.54270345]\n",
      "[0.46074244 0.5392575 ]\n",
      "[0.4641921  0.53580785]\n",
      "[0.40962693 0.590373  ]\n",
      "[0.4197312  0.58026874]\n",
      "[0.40627536 0.59372467]\n",
      "[0.5057612  0.49423876]\n",
      "[0.40962693 0.590373  ]\n",
      "[0.52126575 0.47873428]\n",
      "[0.4814853  0.51851463]\n",
      "[0.49882302 0.50117695]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.4555751 0.5444249]\n",
      "[0.49535394 0.50464606]\n",
      "[0.52692527 0.4730748 ]\n",
      "[0.52501184 0.4749882 ]\n",
      "[0.459019 0.540981]\n",
      "[0.40460274 0.59539723]\n",
      "[0.4555751 0.5444249]\n",
      "[0.49015123 0.5098488 ]\n",
      "[0.44355696 0.55644304]\n",
      "[0.5258462 0.4741538]\n",
      "[0.39483866 0.60516125]\n",
      "[0.412987   0.58701295]\n",
      "[0.459019 0.540981]\n",
      "[0.4299032 0.5700968]\n",
      "[0.49535394 0.50464606]\n",
      "[0.52664703 0.473353  ]\n",
      "[0.4504173 0.5495827]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.40627536 0.59372467]\n",
      "[0.41804224 0.58195776]\n",
      "[0.5022922  0.49770775]\n",
      "[0.5126972 0.4873028]\n",
      "[0.40460274 0.59539723]\n",
      "[0.46074244 0.5392575 ]\n",
      "[0.40127435 0.5987256 ]\n",
      "[0.42480922 0.5751907 ]\n",
      "[0.4504173 0.5495827]\n",
      "[0.49708846 0.50291157]\n",
      "[0.4333075 0.5666925]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.45213547 0.5478646 ]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.4814853  0.51851463]\n",
      "[0.49015123 0.5098488 ]\n",
      "[0.40627536 0.59372467]\n",
      "[0.435012   0.56498796]\n",
      "[0.3980521  0.60194784]\n",
      "[0.524154   0.47584602]\n",
      "[0.4641921  0.53580785]\n",
      "[0.43842563 0.56157434]\n",
      "[0.42142203 0.5785779 ]\n",
      "[0.49535394 0.50464606]\n",
      "[0.45729652 0.54270345]\n",
      "[0.5196283  0.48037165]\n",
      "[0.44698462 0.5530154 ]\n",
      "[0.469373  0.5306271]\n",
      "[0.39644432 0.6035557 ]\n",
      "[0.52393705 0.47606295]\n",
      "[0.459019 0.540981]\n",
      "[0.47283056 0.5271694 ]\n",
      "[0.39966217 0.6003378 ]\n",
      "[0.40795007 0.59204996]\n",
      "[0.4676452 0.5323548]\n",
      "[0.5274008  0.47259927]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.5226706  0.47732928]\n",
      "[0.39483866 0.60516125]\n",
      "[0.5022922  0.49770775]\n",
      "[0.44698462 0.5530154 ]\n",
      "[0.42820352 0.5717965 ]\n",
      "[0.47629082 0.5237092 ]\n",
      "[0.49708846 0.50291157]\n",
      "[0.5005576 0.4994423]\n",
      "[0.44355696 0.55644304]\n",
      "[0.5260744  0.47392562]\n",
      "[0.4265055  0.57349443]\n",
      "[0.52126575 0.47873428]\n",
      "[0.42820352 0.5717965 ]\n",
      "[0.524154   0.47584602]\n",
      "[0.4333075 0.5666925]\n",
      "[0.41804224 0.58195776]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.43842563 0.56157434]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.45213547 0.5478646 ]\n",
      "[0.46591824 0.5340817 ]\n",
      "[0.41804224 0.58195776]\n",
      "[0.46591824 0.5340817 ]\n",
      "[0.41130596 0.58869404]\n",
      "[0.4676452 0.5323548]\n",
      "[0.44698462 0.5530154 ]\n",
      "[0.469373  0.5306271]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.47629082 0.5237092 ]\n",
      "[0.42142203 0.5785779 ]\n",
      "[0.40127435 0.5987256 ]\n",
      "[0.4333075 0.5666925]\n",
      "[0.43671805 0.5632819 ]\n",
      "[0.47629082 0.5237092 ]\n",
      "[0.52393705 0.47606295]\n",
      "[0.39483866 0.60516125]\n",
      "[0.45729652 0.54270345]\n",
      "[0.52126575 0.47873428]\n",
      "[0.5274008  0.47259927]\n",
      "[0.4197312  0.58026874]\n",
      "[0.40962693 0.590373  ]\n",
      "[0.5258462 0.4741538]\n",
      "[0.4504173 0.5495827]\n",
      "[0.43160453 0.5683955 ]\n",
      "[0.43671805 0.5632819 ]\n",
      "[0.5005576 0.4994423]\n",
      "[0.4299032 0.5700968]\n",
      "[0.39966217 0.6003378 ]\n",
      "[0.49535394 0.50464606]\n",
      "[0.39644432 0.6035557 ]\n",
      "[0.49188524 0.5081147 ]\n",
      "[0.5178961  0.48210385]\n",
      "[0.43160453 0.5683955 ]\n",
      "[0.5277735 0.4722265]\n",
      "[0.435012   0.56498796]\n",
      "[0.5161635  0.48383647]\n",
      "[0.41130596 0.58869404]\n",
      "[0.5260744  0.47392562]\n",
      "[0.52501184 0.4749882 ]\n",
      "[0.40460274 0.59539723]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.5238434  0.47615665]\n",
      "[0.52393705 0.47606295]\n",
      "[0.49882302 0.50117695]\n",
      "[0.41804224 0.58195776]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.45385468 0.54614526]\n",
      "[0.5144305  0.48556945]\n",
      "[0.48495063 0.51504934]\n",
      "[0.44355696 0.55644304]\n",
      "[0.48321775 0.51678216]\n",
      "[0.469373  0.5306271]\n",
      "[0.41130596 0.58869404]\n",
      "[0.47283056 0.5271694 ]\n",
      "[0.5057612  0.49423876]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.5277735 0.4722265]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.46074244 0.5392575 ]\n",
      "[0.40127435 0.5987256 ]\n",
      "[0.49015123 0.5098488 ]\n",
      "[0.45213547 0.5478646 ]\n",
      "[0.43160453 0.5683955 ]\n",
      "[0.4197312  0.58026874]\n",
      "[0.49188524 0.5081147 ]\n",
      "[0.412987   0.58701295]\n",
      "[0.435012   0.56498796]\n",
      "[0.4641921  0.53580785]\n",
      "[0.4814853  0.51851463]\n",
      "[0.49535394 0.50464606]\n",
      "[0.49708846 0.50291157]\n",
      "[0.42480922 0.5751907 ]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.4299032 0.5700968]\n",
      "[0.42142203 0.5785779 ]\n",
      "[0.4555751 0.5444249]\n",
      "[0.4814853  0.51851463]\n",
      "[0.44184518 0.5581549 ]\n",
      "[0.4555751 0.5444249]\n",
      "[0.5226706  0.47732928]\n",
      "[0.48321775 0.51678216]\n",
      "[0.41804224 0.58195776]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.4641921  0.53580785]\n",
      "[0.5277735 0.4722265]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.46246684 0.53753316]\n",
      "[0.5178961  0.48210385]\n",
      "[0.5074955  0.49250445]\n",
      "[0.45385468 0.54614526]\n",
      "[0.45729652 0.54270345]\n",
      "[0.5144305  0.48556945]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.46246684 0.53753316]\n",
      "[0.39966217 0.6003378 ]\n",
      "[0.44184518 0.5581549 ]\n",
      "[0.42142203 0.5785779 ]\n",
      "[0.4265055  0.57349443]\n",
      "[0.49188524 0.5081147 ]\n",
      "[0.42142203 0.5785779 ]\n",
      "[0.39483866 0.60516125]\n",
      "[0.40460274 0.59539723]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.49015123 0.5098488 ]\n",
      "[0.5260744  0.47392562]\n",
      "[0.44184518 0.5581549 ]\n",
      "[0.4333075 0.5666925]\n",
      "[0.39966217 0.6003378 ]\n",
      "[0.52501184 0.4749882 ]\n",
      "[0.4163552 0.5836448]\n",
      "[0.4504173 0.5495827]\n",
      "[0.412987   0.58701295]\n",
      "[0.435012   0.56498796]\n",
      "[0.47110146 0.5288986 ]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.5260744  0.47392562]\n",
      "[0.459019 0.540981]\n",
      "[0.524154   0.47584602]\n",
      "[0.43842563 0.56157434]\n",
      "[0.52501184 0.4749882 ]\n",
      "[0.4555751 0.5444249]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.52813846 0.47186154]\n",
      "[0.40795007 0.59204996]\n",
      "[0.43842563 0.56157434]\n",
      "[0.45213547 0.5478646 ]\n",
      "[0.4797533 0.5202466]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.5074955  0.49250445]\n",
      "[0.49015123 0.5098488 ]\n",
      "[0.51096356 0.4890364 ]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.45213547 0.5478646 ]\n",
      "[0.4299032 0.5700968]\n",
      "[0.4333075 0.5666925]\n",
      "[0.524154   0.47584602]\n",
      "[0.5005576 0.4994423]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.40795007 0.59204996]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.44355696 0.55644304]\n",
      "[0.39966217 0.6003378 ]\n",
      "[0.44527015 0.5547299 ]\n",
      "[0.52501184 0.4749882 ]\n",
      "[0.44698462 0.5530154 ]\n",
      "[0.4333075 0.5666925]\n",
      "[0.5196283  0.48037165]\n",
      "[0.43842563 0.56157434]\n",
      "[0.4676452 0.5323548]\n",
      "[0.3980521  0.60194784]\n",
      "[0.4814853  0.51851463]\n",
      "[0.5074955  0.49250445]\n",
      "[0.41130596 0.58869404]\n",
      "[0.52126575 0.47873428]\n",
      "[0.43842563 0.56157434]\n",
      "[0.5258462 0.4741538]\n",
      "[0.42142203 0.5785779 ]\n",
      "[0.5196283  0.48037165]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.49188524 0.5081147 ]\n",
      "[0.5057612  0.49423876]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.5238434  0.47615665]\n",
      "[0.40127435 0.5987256 ]\n",
      "[0.4504173 0.5495827]\n",
      "[0.52664703 0.473353  ]\n",
      "[0.5022922  0.49770775]\n",
      "[0.47110146 0.5288986 ]\n",
      "[0.42820352 0.5717965 ]\n",
      "[0.40460274 0.59539723]\n",
      "[0.43842563 0.56157434]\n",
      "[0.4676452 0.5323548]\n",
      "[0.48321775 0.51678216]\n",
      "[0.44870037 0.5512997 ]\n",
      "[0.5238434  0.47615665]\n",
      "[0.41804224 0.58195776]\n",
      "[0.435012   0.56498796]\n",
      "[0.4504173 0.5495827]\n",
      "[0.4814853  0.51851463]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.48841745 0.5115826 ]\n",
      "[0.4676452 0.5323548]\n",
      "[0.4163552 0.5836448]\n",
      "[0.4504173 0.5495827]\n",
      "[0.41467008 0.5853299 ]\n",
      "[0.42311478 0.5768852 ]\n",
      "[0.40293244 0.5970676 ]\n",
      "[0.42480922 0.5751907 ]\n",
      "[0.48668385 0.5133161 ]\n",
      "[0.5260744  0.47392562]\n",
      "[0.47629082 0.5237092 ]\n",
      "[0.5238434  0.47615665]\n",
      "[0.42142203 0.5785779 ]\n",
      "[0.44013473 0.55986536]\n",
      "[0.5258462 0.4741538]\n",
      "[0.5161635  0.48383647]\n",
      "[0.39644432 0.6035557 ]\n"
     ]
    }
   ],
   "source": [
    "for i in prediction:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_prediction = np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_prediction:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_lables, y_pred=rounded_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91, 119],\n",
       "       [  5, 205]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['no_side_effects','had_side_effects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 91 119]\n",
      " [  5 205]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save and load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.isfile('models/simple_keras_practice.h5') is False:\n",
    "    model.save('models/simple_keras_practice.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above save function saves:\n",
    "- the architecture of the model, allowing to re-create the model\n",
    "- the weights of the model\n",
    "- the training configuration (loss, optimiser)\n",
    "- the state of the optimizer, allowing to resume training exactly where you left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('models/simple_keras_practice.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.49710983,  0.354598  ,  0.37319484, -0.47240058, -0.0167405 ,\n",
       "          0.06792983, -0.15199971, -0.5869865 ,  0.53961504,  0.15826324,\n",
       "         -0.42952675,  0.08803764,  0.45063746,  0.37190497, -0.17935643,\n",
       "          0.13590974]], dtype=float32),\n",
       " array([ 0.        , -0.02497367, -0.01512361,  0.        ,  0.        ,\n",
       "        -0.01069622,  0.        ,  0.        , -0.00628494, -0.01773132,\n",
       "         0.        , -0.00407281,  0.01383105, -0.02288995,  0.        ,\n",
       "        -0.01482442], dtype=float32),\n",
       " array([[-0.26878285,  0.14940932, -0.06762376, -0.17764838, -0.00959632,\n",
       "          0.17518952, -0.29728624,  0.20102844, -0.28856808, -0.17025624,\n",
       "          0.01919866,  0.21566519,  0.14160094,  0.07198775, -0.00590974,\n",
       "         -0.28197464,  0.15839103,  0.20193407, -0.20994677, -0.3101703 ,\n",
       "         -0.11915798, -0.24479412,  0.2765313 , -0.12614636,  0.20270374,\n",
       "          0.23408958,  0.25232145, -0.34012195,  0.01593217,  0.30510584,\n",
       "          0.0761483 , -0.2832012 ],\n",
       "        [-0.35291857, -0.21620162,  0.24579519,  0.16670561,  0.19758537,\n",
       "          0.3603415 ,  0.04229347,  0.01150432,  0.00203562, -0.30118212,\n",
       "          0.09568585,  0.05111305,  0.20048614, -0.08568557,  0.35741314,\n",
       "         -0.17896175, -0.02773026,  0.08517727, -0.24692033,  0.33680022,\n",
       "         -0.0684877 , -0.2508028 , -0.13834989, -0.22980924,  0.3179342 ,\n",
       "          0.06075858,  0.00836881, -0.246434  , -0.29982626,  0.19048193,\n",
       "         -0.2781258 ,  0.02220795],\n",
       "        [-0.2575399 , -0.24480794,  0.15939192,  0.20039868,  0.29357752,\n",
       "         -0.2318606 ,  0.24611633,  0.07979596, -0.29620975, -0.09449673,\n",
       "         -0.16703328,  0.35012242,  0.2258539 , -0.29018992,  0.30478194,\n",
       "          0.25967118,  0.32025704, -0.07114142,  0.20467988,  0.11705068,\n",
       "          0.35485718,  0.17559104, -0.05411928, -0.28903818,  0.14521018,\n",
       "         -0.34880805,  0.2639968 ,  0.12092753,  0.1190328 , -0.32705936,\n",
       "         -0.09556318, -0.17026214],\n",
       "        [ 0.09735215, -0.07015046,  0.25746962, -0.3490344 ,  0.02859756,\n",
       "          0.296212  , -0.33312827, -0.08582497,  0.23418811, -0.14489041,\n",
       "         -0.05542883,  0.05416358,  0.3183433 ,  0.08531475, -0.23821567,\n",
       "         -0.00095832,  0.27393827,  0.23595801, -0.1466202 , -0.23387715,\n",
       "         -0.16944052, -0.10157889, -0.3020061 ,  0.05692834,  0.06236124,\n",
       "          0.0540739 , -0.32467353,  0.04284742,  0.33088878, -0.05539426,\n",
       "         -0.34137675, -0.22620264],\n",
       "        [-0.25696772, -0.2976907 , -0.21268445,  0.078345  ,  0.18091115,\n",
       "          0.05133933,  0.12600923, -0.35195273, -0.10288787,  0.01711753,\n",
       "         -0.2364976 , -0.24884595,  0.341925  , -0.21820122, -0.3018371 ,\n",
       "          0.08610189,  0.08907348,  0.26218018, -0.09494615, -0.32420096,\n",
       "         -0.28988957,  0.12556177, -0.01374003,  0.27946422,  0.00751343,\n",
       "          0.34474054, -0.26832208, -0.26906395,  0.05879384, -0.19817692,\n",
       "          0.17457393,  0.18555704],\n",
       "        [-0.08854201, -0.01597711, -0.11434531,  0.10440943, -0.15378238,\n",
       "         -0.20628266, -0.05545256,  0.32707945, -0.04121482, -0.16409661,\n",
       "          0.15901591,  0.34190777,  0.04848891,  0.3218343 ,  0.23565908,\n",
       "          0.05430993, -0.32225758, -0.15689206,  0.10239103, -0.06469984,\n",
       "          0.23343836,  0.36252603, -0.13565052,  0.16940506, -0.1618206 ,\n",
       "         -0.08551579, -0.286196  , -0.21094042, -0.12812878,  0.33687124,\n",
       "          0.29627213, -0.27169174],\n",
       "        [ 0.17108348, -0.35267192, -0.01874331,  0.18591371,  0.07163507,\n",
       "         -0.13817127,  0.17058036,  0.19089445, -0.21380489, -0.3251325 ,\n",
       "          0.33994874,  0.33188435, -0.11266206,  0.1261858 , -0.09502545,\n",
       "         -0.08263808,  0.01638949, -0.11306432, -0.2748676 , -0.23403952,\n",
       "         -0.0191935 ,  0.04429287,  0.17661694,  0.1053485 ,  0.24849764,\n",
       "          0.30366334, -0.12733355, -0.05916607,  0.06453702,  0.11255106,\n",
       "          0.29111555,  0.30653933],\n",
       "        [-0.29644608, -0.22334315, -0.25364074,  0.34250358,  0.2555571 ,\n",
       "          0.0819746 , -0.22764498, -0.08383068,  0.02623212, -0.13001469,\n",
       "          0.07022575, -0.27011392,  0.01604918,  0.07807568, -0.1585599 ,\n",
       "         -0.18861616, -0.14934921,  0.15921631, -0.07012939,  0.12452015,\n",
       "          0.15610829,  0.18885109,  0.3062457 , -0.24494913,  0.00937775,\n",
       "          0.18104902,  0.1263248 ,  0.05316773,  0.14705345,  0.10743856,\n",
       "          0.1934211 , -0.11109158],\n",
       "        [ 0.19634517, -0.18917242,  0.22227952, -0.01552426, -0.22364593,\n",
       "          0.32502958,  0.1567579 , -0.20163187, -0.23850463,  0.19342625,\n",
       "          0.2539487 , -0.0479682 , -0.035533  ,  0.17325442, -0.17824484,\n",
       "         -0.28520888, -0.25115636, -0.22529867, -0.12205479,  0.17052755,\n",
       "          0.06842567,  0.31053913,  0.1028144 ,  0.27814305,  0.23504347,\n",
       "         -0.01602145,  0.33950073,  0.23415565, -0.21583788, -0.03567106,\n",
       "          0.07365362, -0.10022706],\n",
       "        [-0.21656449,  0.24594322,  0.07240363,  0.15168259, -0.12511781,\n",
       "          0.07679508,  0.09408516, -0.29663652, -0.19732277, -0.0549741 ,\n",
       "         -0.11003605,  0.06635982,  0.12878208, -0.04432925,  0.05449377,\n",
       "          0.09881335, -0.1853846 , -0.29812092, -0.04000666,  0.25953823,\n",
       "         -0.08087341,  0.24337412, -0.22696179, -0.01997699, -0.1630389 ,\n",
       "         -0.0188711 ,  0.15306917,  0.10728241, -0.14865766, -0.25501996,\n",
       "          0.22456346, -0.11237496],\n",
       "        [ 0.31740132, -0.15257673,  0.28613326,  0.05027294,  0.32989576,\n",
       "         -0.15214144, -0.16911145, -0.24588454,  0.25139973,  0.02031603,\n",
       "         -0.13562182,  0.24736956,  0.35148892, -0.02466398,  0.296167  ,\n",
       "         -0.21339725, -0.13113292,  0.05779555, -0.25057617, -0.10750514,\n",
       "          0.0644106 , -0.19459873, -0.08768973, -0.00359917, -0.00814226,\n",
       "         -0.24540618,  0.13743168, -0.183496  , -0.03536585,  0.01845559,\n",
       "         -0.22017033,  0.33255354],\n",
       "        [ 0.06695098, -0.1732565 , -0.27996537, -0.27607197, -0.20106255,\n",
       "          0.06117875,  0.22368859, -0.31986785,  0.22629216,  0.18439625,\n",
       "          0.2160342 ,  0.02436538, -0.1553933 , -0.20821555,  0.36675376,\n",
       "         -0.13129796, -0.29094642, -0.2130937 , -0.22738314, -0.1705626 ,\n",
       "         -0.03465205, -0.3146002 , -0.13025948,  0.28869778, -0.24442087,\n",
       "         -0.0673756 ,  0.24549523, -0.2888613 , -0.27701902, -0.25472948,\n",
       "          0.02182148, -0.06781596],\n",
       "        [ 0.18770471, -0.1622268 ,  0.21481176,  0.19107483, -0.32592165,\n",
       "          0.24203049,  0.14923768, -0.12229489,  0.18194199,  0.19577771,\n",
       "          0.16731209,  0.07730646,  0.29091263,  0.34365013,  0.02952214,\n",
       "         -0.13822615, -0.28814685, -0.31405392,  0.05176359, -0.070264  ,\n",
       "         -0.13468467,  0.18630709,  0.32068604, -0.1156884 , -0.2652295 ,\n",
       "         -0.0941857 , -0.30908275, -0.14276102, -0.09089579, -0.06794827,\n",
       "         -0.03118664, -0.27603582],\n",
       "        [ 0.07596359,  0.21280393,  0.24798524, -0.2540418 , -0.03089795,\n",
       "          0.08766112,  0.262834  , -0.2932629 , -0.05246242,  0.04655441,\n",
       "         -0.03271327, -0.05096496, -0.03267286, -0.20885594, -0.14462517,\n",
       "         -0.34803054, -0.06188598,  0.25325623,  0.32504323, -0.2846548 ,\n",
       "          0.18555067, -0.25976115,  0.22108404, -0.11066405, -0.3011608 ,\n",
       "          0.31463924, -0.09478195,  0.06229373,  0.03148075,  0.29272637,\n",
       "          0.01778817, -0.0651924 ],\n",
       "        [ 0.07067698,  0.1608012 , -0.13936622, -0.0448885 , -0.12068245,\n",
       "          0.12357068, -0.14331613,  0.25065318, -0.08841556, -0.14275019,\n",
       "          0.06123844,  0.23838285, -0.265581  , -0.09996068,  0.30203155,\n",
       "          0.14077881, -0.1484482 , -0.00533646, -0.34146094, -0.00074095,\n",
       "         -0.10118219,  0.12603837,  0.3196405 , -0.24365869, -0.09880662,\n",
       "         -0.29171452, -0.19352645, -0.07720011,  0.07224923,  0.0680224 ,\n",
       "         -0.17064382,  0.27954116],\n",
       "        [-0.13935308,  0.22643396,  0.09887759,  0.03752389,  0.12510753,\n",
       "         -0.00885981,  0.32270324, -0.09168532,  0.2630889 ,  0.10595772,\n",
       "         -0.27825633,  0.28957644, -0.1456595 ,  0.09152599,  0.24246183,\n",
       "          0.20958051,  0.27163312,  0.18519536, -0.05164113, -0.33772138,\n",
       "         -0.29258633,  0.09237927, -0.33112115,  0.30481783,  0.27763337,\n",
       "          0.28406507,  0.0924653 , -0.15390041, -0.02306563, -0.07384261,\n",
       "         -0.22766542,  0.33011052]], dtype=float32),\n",
       " array([ 3.4204263e-02, -5.7171134e-04, -1.8398710e-02,  2.1295743e-02,\n",
       "         0.0000000e+00, -2.3188356e-02, -1.7376907e-02,  0.0000000e+00,\n",
       "        -2.8317512e-03,  2.1785351e-02, -1.5947184e-02, -1.3157775e-02,\n",
       "         1.9961927e-02, -1.6742902e-02, -1.2298787e-02,  0.0000000e+00,\n",
       "         0.0000000e+00, -5.7174981e-04,  1.9700775e-02,  2.1629645e-02,\n",
       "        -1.0777568e-02, -1.8589828e-02,  2.1668553e-02, -2.3669121e-03,\n",
       "         2.0711061e-02, -6.6700697e-05, -1.0710230e-02,  2.2046806e-02,\n",
       "        -5.7173875e-04,  4.1881922e-05, -5.2235537e-04,  0.0000000e+00],\n",
       "       dtype=float32),\n",
       " array([[-0.07357395, -0.42215145],\n",
       "        [-0.20963235,  0.17327859],\n",
       "        [-0.32755622,  0.13317464],\n",
       "        [ 0.24043177,  0.07724165],\n",
       "        [ 0.37364677, -0.01085889],\n",
       "        [ 0.36584252,  0.39221734],\n",
       "        [-0.42587385,  0.0753895 ],\n",
       "        [ 0.16231045, -0.01712966],\n",
       "        [-0.18646199,  0.10455827],\n",
       "        [ 0.40583447, -0.17149682],\n",
       "        [-0.23928902,  0.06856798],\n",
       "        [-0.17541242,  0.18678188],\n",
       "        [ 0.3714754 ,  0.32145894],\n",
       "        [-0.34477565,  0.23061897],\n",
       "        [-0.25229517, -0.19029632],\n",
       "        [ 0.2623562 ,  0.39656946],\n",
       "        [-0.24857938,  0.08205435],\n",
       "        [-0.3657757 ,  0.27628514],\n",
       "        [-0.18673706, -0.21500583],\n",
       "        [ 0.25398836, -0.09671234],\n",
       "        [-0.3529385 , -0.12033056],\n",
       "        [ 0.17074274,  0.35496533],\n",
       "        [ 0.00566948, -0.3257866 ],\n",
       "        [ 0.03030649,  0.39361045],\n",
       "        [ 0.2517499 ,  0.18161966],\n",
       "        [ 0.4174167 , -0.37955707],\n",
       "        [-0.22038305,  0.36198452],\n",
       "        [ 0.29594427,  0.20444824],\n",
       "        [-0.39295778,  0.14567293],\n",
       "        [ 0.33375597, -0.06879935],\n",
       "        [ 0.23589306,  0.38739493],\n",
       "        [-0.3235369 , -0.18118933]], dtype=float32),\n",
       " array([ 0.02193264, -0.02193264], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7ff67cd342d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save as json\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backend: tensorflow\\nclass_name: Sequential\\nconfig:\\n  layers:\\n  - class_name: Dense\\n    config:\\n      activation: relu\\n      activity_regularizer: null\\n      batch_input_shape: !!python/tuple\\n      - null\\n      - 1\\n      bias_constraint: null\\n      bias_initializer:\\n        class_name: Zeros\\n        config: {}\\n      bias_regularizer: null\\n      dtype: float32\\n      kernel_constraint: null\\n      kernel_initializer:\\n        class_name: GlorotUniform\\n        config:\\n          seed: null\\n      kernel_regularizer: null\\n      name: dense\\n      trainable: true\\n      units: 16\\n      use_bias: true\\n  - class_name: Dense\\n    config:\\n      activation: relu\\n      activity_regularizer: null\\n      bias_constraint: null\\n      bias_initializer:\\n        class_name: Zeros\\n        config: {}\\n      bias_regularizer: null\\n      dtype: float32\\n      kernel_constraint: null\\n      kernel_initializer:\\n        class_name: GlorotUniform\\n        config:\\n          seed: null\\n      kernel_regularizer: null\\n      name: dense_1\\n      trainable: true\\n      units: 32\\n      use_bias: true\\n  - class_name: Dense\\n    config:\\n      activation: softmax\\n      activity_regularizer: null\\n      bias_constraint: null\\n      bias_initializer:\\n        class_name: Zeros\\n        config: {}\\n      bias_regularizer: null\\n      dtype: float32\\n      kernel_constraint: null\\n      kernel_initializer:\\n        class_name: GlorotUniform\\n        config:\\n          seed: null\\n      kernel_regularizer: null\\n      name: dense_2\\n      trainable: true\\n      units: 2\\n      use_bias: true\\n  name: sequential\\nkeras_version: 2.2.4-tf\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save as yaml\n",
    "yaml_string = model.to_yaml()\n",
    "yaml_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/keras_env/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "# model reconstruction from json\n",
    "# from json only saves architecture, weights etc are not saved\n",
    "from tensorflow.keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)\n",
    "\n",
    "# model reconstruction from yaml\n",
    "from tensorflow.keras.models import model_from_yaml\n",
    "model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.isfile('models/model_weights.h5') is False:\n",
    "    model.save_weights('models/model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('models/model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.5572777 , -0.02278548,  0.05336648,  0.10687804, -0.01228344,\n",
       "         -0.48404565,  0.51769936,  0.24066871,  0.23061502, -0.00227958,\n",
       "          0.21147847,  0.23155892, -0.37291297,  0.36316395, -0.51856345,\n",
       "         -0.3711195 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.10706016, -0.02012715,  0.01155254, -0.22277728,  0.21600446,\n",
       "         -0.20585473, -0.30849662, -0.15809248,  0.2653241 ,  0.01006687,\n",
       "          0.25792798,  0.17643538,  0.01563191, -0.11799018, -0.14143859,\n",
       "          0.00131565,  0.05524245, -0.22326146, -0.2899983 , -0.02770001,\n",
       "         -0.22260624, -0.23123084,  0.18621674, -0.15553316, -0.15819077,\n",
       "          0.12085861, -0.00678369,  0.13339055, -0.2767207 , -0.14354517,\n",
       "         -0.17832002, -0.239269  ],\n",
       "        [-0.07243264,  0.02567956, -0.22776873,  0.01083359,  0.15863177,\n",
       "          0.02138549,  0.31097773, -0.0033167 ,  0.35251638,  0.34269956,\n",
       "         -0.32455266,  0.24633196,  0.29921582,  0.18068025,  0.34816995,\n",
       "          0.11060858, -0.03540513,  0.14717075, -0.12508425, -0.10107017,\n",
       "         -0.18451907,  0.03456843, -0.18378234,  0.33028004,  0.11847842,\n",
       "         -0.04019049,  0.2239134 ,  0.16743502, -0.25650436,  0.17089662,\n",
       "         -0.06306189, -0.25618878],\n",
       "        [ 0.21750268,  0.15725729,  0.14504829,  0.12790439,  0.3279017 ,\n",
       "          0.19592854,  0.32727847, -0.2991841 , -0.19545011,  0.23025414,\n",
       "          0.10033581, -0.06574959, -0.24843156,  0.35046235,  0.06133959,\n",
       "          0.05866185,  0.05751696, -0.30780265,  0.19591525, -0.09812224,\n",
       "          0.19218895, -0.23171148,  0.16768107,  0.13042915,  0.22300646,\n",
       "          0.21669534, -0.25047383, -0.23794003, -0.13100293, -0.08716837,\n",
       "          0.29922292,  0.24355122],\n",
       "        [ 0.04423878,  0.11571813, -0.23648033,  0.22538808,  0.22573301,\n",
       "         -0.2750559 , -0.28415996,  0.16416737, -0.03854516, -0.2347603 ,\n",
       "         -0.1276408 , -0.13822244,  0.0171445 ,  0.05038252, -0.11399753,\n",
       "         -0.01637599, -0.16144232, -0.02642193, -0.19686161, -0.26920247,\n",
       "         -0.09617329,  0.22134587, -0.1913005 ,  0.00650251,  0.06103402,\n",
       "         -0.35061145, -0.01257998, -0.02639177,  0.30308947, -0.2892797 ,\n",
       "          0.08893415,  0.33532587],\n",
       "        [-0.04216439, -0.2391687 , -0.01338315, -0.2639164 , -0.28832793,\n",
       "          0.17238274, -0.11098866,  0.32590708,  0.1061379 ,  0.33559105,\n",
       "          0.23137358,  0.08255193, -0.12817346, -0.18055955,  0.18669555,\n",
       "          0.07807761, -0.02017865,  0.20990655,  0.01890877, -0.07182041,\n",
       "         -0.17910025, -0.25719893,  0.06280023, -0.3115994 ,  0.1581873 ,\n",
       "         -0.2958841 ,  0.03090477, -0.14085746, -0.27002794, -0.08491501,\n",
       "         -0.27969685,  0.06232989],\n",
       "        [-0.29045728,  0.21065536, -0.19192874, -0.1390487 ,  0.08244723,\n",
       "         -0.30424732,  0.25909033,  0.10051635, -0.13931851, -0.1880964 ,\n",
       "          0.1753358 ,  0.10779157,  0.26797017, -0.08096832, -0.18624869,\n",
       "          0.19712839,  0.0902788 , -0.23142505,  0.33134332, -0.27050725,\n",
       "          0.06471294, -0.09274793, -0.10875244,  0.05694646, -0.03092912,\n",
       "          0.10405105,  0.27364066, -0.19229086,  0.17129466,  0.16028664,\n",
       "         -0.28137648, -0.19762994],\n",
       "        [-0.08805826,  0.23248944,  0.05866531,  0.23426965,  0.03583166,\n",
       "          0.29261234,  0.05560812, -0.06862172, -0.34977752,  0.2711284 ,\n",
       "         -0.04378527, -0.22224614,  0.18372682,  0.20857683,  0.18124947,\n",
       "          0.13723207, -0.29767662,  0.15624788, -0.03177661, -0.16458909,\n",
       "          0.31903556, -0.06721655, -0.09202698,  0.34665897,  0.01110265,\n",
       "         -0.00484368, -0.25514993,  0.29664585, -0.34085798,  0.19648144,\n",
       "          0.06359917, -0.03438339],\n",
       "        [-0.3457574 , -0.26701874,  0.05724326,  0.01983795, -0.11403714,\n",
       "          0.24845055, -0.23274425,  0.08459368, -0.29871544,  0.23927447,\n",
       "         -0.19931582,  0.25034645,  0.2827944 , -0.29220283,  0.23612723,\n",
       "         -0.08799621,  0.02545038,  0.07190058, -0.14268403, -0.04973453,\n",
       "          0.11094382,  0.31216827, -0.22958139, -0.3204916 , -0.27888307,\n",
       "         -0.30874607, -0.06870848, -0.09448799, -0.19023174, -0.04250559,\n",
       "         -0.15401874,  0.2908388 ],\n",
       "        [-0.20284772, -0.16282263,  0.1778126 ,  0.33725265,  0.30148003,\n",
       "          0.32658377, -0.15247793,  0.15786454,  0.05931991, -0.09282044,\n",
       "          0.1272856 , -0.12038606, -0.04569781, -0.05289641,  0.09070888,\n",
       "          0.13352248,  0.06598064,  0.14138716, -0.03321257,  0.3122032 ,\n",
       "          0.22439519,  0.23720542, -0.08488274, -0.3280601 ,  0.30047616,\n",
       "         -0.14798787,  0.1102066 ,  0.24240997,  0.05036312, -0.2066518 ,\n",
       "         -0.03562799,  0.3343629 ],\n",
       "        [ 0.23807546,  0.33074865, -0.25438035,  0.09773254, -0.08184135,\n",
       "          0.19678184, -0.3427601 , -0.16607738,  0.25416943, -0.17634983,\n",
       "          0.13756233, -0.2539844 ,  0.19238916, -0.18909664, -0.19645455,\n",
       "          0.19520256,  0.32467595, -0.13908418, -0.19940938,  0.2021294 ,\n",
       "          0.23355499, -0.05782178, -0.23658729, -0.22636019,  0.0287202 ,\n",
       "         -0.02957451,  0.2543263 , -0.33161476,  0.02110538, -0.10703631,\n",
       "          0.1260243 , -0.20057179],\n",
       "        [-0.329747  ,  0.31461027,  0.3488867 ,  0.06386974,  0.3248324 ,\n",
       "         -0.02378607,  0.2933857 ,  0.29349044, -0.19838749, -0.09139022,\n",
       "         -0.1113379 ,  0.2043778 ,  0.30858424, -0.28987598,  0.08845621,\n",
       "         -0.15264037, -0.16443138, -0.21152845, -0.2081304 , -0.05000007,\n",
       "         -0.25757456,  0.20279697,  0.01582116, -0.19792286,  0.3150644 ,\n",
       "         -0.01280144,  0.32988784,  0.34404346, -0.34501544, -0.13515238,\n",
       "          0.21360299, -0.10718086],\n",
       "        [-0.2472899 , -0.30149832, -0.20410842, -0.32670856, -0.3256945 ,\n",
       "         -0.2645439 ,  0.22811183,  0.34179005,  0.010261  , -0.2635492 ,\n",
       "          0.24078056, -0.18373573, -0.3324422 ,  0.19561192, -0.16032821,\n",
       "          0.24542698, -0.24798986,  0.17359552, -0.17702721, -0.3433278 ,\n",
       "         -0.177199  , -0.33055234, -0.08004427,  0.03251207, -0.0319806 ,\n",
       "          0.14435142,  0.13222149,  0.1636897 ,  0.03694585, -0.33033225,\n",
       "         -0.10872993,  0.11349201],\n",
       "        [-0.10785808, -0.3439697 , -0.03831553,  0.01469922,  0.25848922,\n",
       "         -0.31758106,  0.24295315, -0.04303792, -0.34623948,  0.15157631,\n",
       "          0.21769777, -0.21484321, -0.23289631, -0.09484357, -0.08479989,\n",
       "          0.34399387,  0.07407621,  0.13402513, -0.33299044, -0.11132762,\n",
       "          0.04077843, -0.11159407,  0.1020655 , -0.34069952, -0.06215808,\n",
       "         -0.04552719,  0.11302412,  0.17271939, -0.10719663,  0.03363302,\n",
       "         -0.20203605, -0.2320678 ],\n",
       "        [-0.03493974,  0.02219421, -0.12397681, -0.11698928,  0.0404276 ,\n",
       "          0.09358943,  0.32268456,  0.03038222,  0.07166591,  0.17464164,\n",
       "          0.18916002,  0.10694441,  0.10463867,  0.3209481 ,  0.16174224,\n",
       "         -0.2127169 , -0.01003644,  0.2960933 , -0.31816968,  0.13641712,\n",
       "          0.330151  , -0.14778328,  0.27409795,  0.00372553,  0.24106035,\n",
       "          0.08337682,  0.22644272, -0.18861987, -0.071345  ,  0.0829944 ,\n",
       "         -0.21789339, -0.2980561 ],\n",
       "        [ 0.15784171, -0.27377108,  0.13340262,  0.23601064,  0.10816228,\n",
       "         -0.23798454,  0.13692263, -0.21735871, -0.2607967 , -0.05005959,\n",
       "          0.11995441, -0.30257636,  0.2766553 , -0.11271627,  0.03827634,\n",
       "         -0.00540474,  0.03712574, -0.3388968 ,  0.18187007,  0.1754354 ,\n",
       "          0.08772564,  0.2252802 ,  0.05113956, -0.16148186, -0.17150766,\n",
       "         -0.27058792,  0.34246674, -0.01475435, -0.21770482, -0.31958658,\n",
       "         -0.19897164,  0.1380477 ],\n",
       "        [-0.09100726,  0.27058294, -0.15104276,  0.17320845,  0.17339745,\n",
       "         -0.19534793,  0.24829838, -0.21403661, -0.2306423 , -0.33660048,\n",
       "         -0.10224608,  0.31302008,  0.00063869, -0.1917422 ,  0.16857418,\n",
       "          0.2246463 , -0.32983777, -0.18347417, -0.31320882, -0.33686855,\n",
       "          0.139011  ,  0.05405325, -0.16278403, -0.00219661, -0.2937975 ,\n",
       "         -0.23294806, -0.17611313, -0.20068423, -0.07327551, -0.272988  ,\n",
       "          0.10407415,  0.01393712]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[-0.3385667 ,  0.05070901],\n",
       "        [-0.2390189 , -0.3047679 ],\n",
       "        [ 0.2657543 , -0.365171  ],\n",
       "        [-0.03040582,  0.28243646],\n",
       "        [-0.3716717 ,  0.377367  ],\n",
       "        [ 0.35151026,  0.39222357],\n",
       "        [ 0.098263  , -0.25607875],\n",
       "        [ 0.36131266,  0.3003858 ],\n",
       "        [-0.31019494,  0.02478558],\n",
       "        [-0.38992772, -0.30392277],\n",
       "        [-0.37353742, -0.35480866],\n",
       "        [ 0.2209414 ,  0.19951436],\n",
       "        [ 0.22910026, -0.11206657],\n",
       "        [-0.31163368,  0.27325127],\n",
       "        [-0.04687604,  0.4075974 ],\n",
       "        [ 0.14217243, -0.3563221 ],\n",
       "        [-0.20363796,  0.3486701 ],\n",
       "        [-0.29508555, -0.1097101 ],\n",
       "        [-0.33283588, -0.07286268],\n",
       "        [-0.29139298,  0.02752754],\n",
       "        [-0.20884465,  0.3530216 ],\n",
       "        [-0.3925563 ,  0.39255688],\n",
       "        [ 0.3507975 , -0.24511358],\n",
       "        [-0.28670138, -0.18363874],\n",
       "        [-0.34023008,  0.06804746],\n",
       "        [ 0.02092957,  0.25787744],\n",
       "        [ 0.2873986 , -0.38365445],\n",
       "        [ 0.12076542, -0.14442313],\n",
       "        [ 0.4072928 ,  0.07897618],\n",
       "        [-0.3192815 ,  0.2516891 ],\n",
       "        [-0.339994  ,  0.40601555],\n",
       "        [-0.29584453,  0.38378152]], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "keras_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
